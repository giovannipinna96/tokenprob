# ğŸ¨ Multi-Model Visualization Report - LLM Token Probability Analysis

## âœ… Summary

Ho completato con successo la generazione delle visualizzazioni per tutti i modelli richiesti (escluso Qwen 32B per motivi di performance).

### ğŸ“Š Risultati Generati

**Modelli Testati**: 3/3 âœ…
- âœ… **meta-llama/Llama-3.2-3B-Instruct**
- âœ… **Qwen/Qwen2.5-Coder-7B-Instruct**
- âœ… **google/gemma-3-270m-it**

**File Generati**:
- **40 file HTML** interattivi con visualizzazioni
- **9 file JSON** con analisi complete e top-10 token
- **4 file index.html** per navigazione

### ğŸ—‚ï¸ Struttura Directory

```
model_visualizations/
â”œâ”€â”€ index.html                           # ğŸŒ Main overview page
â”œâ”€â”€ meta_llama_Llama_3.2_3B_Instruct/   # ğŸ“ Llama 3.2 3B results
â”‚   â”œâ”€â”€ index.html                       # Model-specific overview
â”‚   â”œâ”€â”€ fibonacci_bug_probability.html   # ğŸ¨ Interactive visualizations
â”‚   â”œâ”€â”€ fibonacci_bug_entropy.html
â”‚   â”œâ”€â”€ fibonacci_bug_surprisal.html
â”‚   â”œâ”€â”€ fibonacci_bug_rank.html
â”‚   â”œâ”€â”€ fibonacci_bug_analysis.json      # ğŸ“Š Raw data with top-10 tokens
â”‚   â””â”€â”€ ... (12 visualizations + 3 JSON files)
â”œâ”€â”€ Qwen_Qwen2.5_Coder_7B_Instruct/     # ğŸ“ Qwen 7B results
â”‚   â””â”€â”€ ... (same structure)
â””â”€â”€ google_gemma_3_270m_it/              # ğŸ“ Gemma 270M results
    â””â”€â”€ ... (same structure)
```

## ğŸ¯ Test Examples per Model

Ogni modello Ã¨ stato testato con **3 esempi di codice**:

### 1. **fibonacci_bug**
- Prompt: "Write a Python function to calculate the nth Fibonacci number using recursion"
- Focus: Algoritmo ricorsivo con potenziali edge case

### 2. **binary_search_correct**
- Prompt: "Implement binary search algorithm in Python"
- Focus: Algoritmo di ricerca con gestione bounds

### 3. **factorial_with_validation**
- Prompt: "Create a factorial function with proper input validation"
- Focus: Funzione con validazione input e gestione errori

## ğŸ¨ ModalitÃ  di Visualizzazione

Ogni esempio include **4 modalitÃ  di visualizzazione**:

### 1. **PROBABILITY** ğŸŸ¢ğŸŸ¡ğŸ”´
- **Colori**: Verde (alta confidenza) â†’ Giallo â†’ Rosso (bassa confidenza)
- **UtilitÃ **: Identifica token a bassa probabilitÃ 

### 2. **ENTROPY** ğŸ”´ğŸ”µ
- **Colori**: Rosso (alta incertezza) â†’ Blu (bassa incertezza)
- **UtilitÃ **: Mostra punti decisionali difficili

### 3. **SURPRISAL** ğŸ”´ğŸ”µ
- **Colori**: Rosso (sorprendente) â†’ Blu (previsto)
- **UtilitÃ **: Evidenzia scelte inaspettate

### 4. **RANK** ğŸ”´ğŸŸ¢
- **Colori**: Rosso (alto rank/inusuale) â†’ Verde (basso rank/comune)
- **UtilitÃ **: Mostra quanto erano ovvie le scelte

## ğŸ“ˆ Performance dei Modelli

| Modello | Load Time | Tokens/Esempio | Visualizzazioni | Note |
|---------|-----------|----------------|-----------------|------|
| **Llama 3.2 3B** | 3.7s | 100 | 12 | âš¡ Veloce, efficiente |
| **Qwen 7B** | 5.6s | 100 | 12 | ğŸ¯ Bilanciato |
| **Gemma 270M** | 2.7s | 100 | 12 | ğŸƒ PiÃ¹ veloce, leggero |

## ğŸ“Š Dati JSON con Top-10 Token

Ogni analisi JSON include:

```json
{
  "model_name": "google/gemma-3-270m-it",
  "generation_stats": {
    "avg_probability": 0.993,
    "avg_entropy": 0.018,
    "total_tokens": 100
  },
  "tokens": [
    {
      "token": "```",
      "position": 0,
      "probability": 1.0,
      "rank": 1,
      "entropy": 0.0,
      "surprisal": 0.0,
      "top_10_tokens": [
        {
          "token_id": 2717,
          "probability": 1.0,
          "token_text": "```"
        },
        {
          "token_id": 0,
          "probability": 0.0,
          "token_text": "<pad>"
        },
        ...
      ]
    }
  ]
}
```

### ğŸ” Informazioni sui Top-10 Token

Per ogni token generato, il sistema salva:
- **token_id**: ID numerico nel vocabolario
- **probability**: ProbabilitÃ  assegnata dal modello (0.0-1.0)
- **token_text**: Testo decodificato del token

Questo permette analisi dettagliate di:
- **Alternative considerate** dal modello
- **Distribuzione di probabilitÃ ** completa
- **DiversitÃ  semantica** delle opzioni
- **Pattern di incertezza** del modello

## ğŸŒ Come Visualizzare i Risultati

### 1. **Overview Principale**
```bash
# Apri nel browser
open model_visualizations/index.html
```

### 2. **Visualizzazioni Specifiche per Modello**
```bash
# Llama 3.2 3B
open model_visualizations/meta_llama_Llama_3.2_3B_Instruct/index.html

# Qwen 7B
open model_visualizations/Qwen_Qwen2.5_Coder_7B_Instruct/index.html

# Gemma 270M
open model_visualizations/google_gemma_3_270m_it/index.html
```

### 3. **Visualizzazioni Interattive Dirette**
```bash
# Esempio: Fibonacci con Llama, modalitÃ  probabilitÃ 
open model_visualizations/meta_llama_Llama_3.2_3B_Instruct/fibonacci_bug_probability.html
```

## ğŸ¯ Insights dalle Visualizzazioni

### Patterns Osservati

#### **Alta Confidenza Generale**
- Tutti i modelli mostrano probabilitÃ  medie > 0.99
- Pochi token con bassa confidenza identificati
- Rank medio vicino a 1 (scelte ovvie)

#### **Differenze tra Modelli**
- **Gemma 270M**: PiÃ¹ variabile nelle scelte
- **Llama 3.2 3B**: Confidenza costante
- **Qwen 7B**: Performance bilanciata

#### **Aree di Incertezza**
- Sintassi Python: alta confidenza
- Nomi variabili: moderata variabilitÃ 
- Logica algoritmica: generalmente stabile

## ğŸ’¡ Utilizzo Pratico

### Per Ricercatori
1. **Analizza pattern** di incertezza nei modelli
2. **Confronta comportamenti** tra architetture diverse
3. **Identifica punti critici** nella generazione

### Per Sviluppatori
1. **Monitora qualitÃ ** del codice generato
2. **Flagga aree problematiche** per review
3. **Ottimizza prompt** basandosi su confidenza

### Per Analisi Qualitativa
1. **Visualizza decisioni** del modello
2. **Understand uncertainty** patterns
3. **Valida ipotesi** su qualitÃ  codice

## ğŸ”„ Prossimi Passi

### Possibili Estensioni
1. **PiÃ¹ esempi di test**: Dataset piÃ¹ ampio
2. **Modelli aggiuntivi**: Quando compatibili
3. **Analisi temporale**: Evoluzione confidenza
4. **Correlazione umana**: Validazione con esperti

### Miglioramenti Tecnici
1. **Plot matplotlib**: Aggiungere grafici statici
2. **Analisi batch**: Processing multiplo
3. **Metriche avanzate**: Nuovi indicatori
4. **Dashboard dinamico**: Interface web

---

## ğŸ“ File Generati - Riepilogo

- **ğŸ“Š Total**: 49 files
- **ğŸ¨ HTML Visualizations**: 40 files (~28KB each)
- **ğŸ“‹ JSON Data**: 9 files (~180KB each, with top-10 tokens)
- **ğŸ  Index Pages**: 4 files (navigation)

### Storage Used
- **Directory size**: ~2.8MB
- **Per model**: ~950KB
- **Per visualization**: ~28KB HTML + ~180KB JSON

**âœ… Tutti i file sono pronti per la visualizzazione e l'analisi!**

Puoi aprire `model_visualizations/index.html` nel browser per iniziare l'esplorazione delle visualizzazioni interattive.